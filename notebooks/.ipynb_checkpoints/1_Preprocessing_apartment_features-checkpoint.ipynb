{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas:\n",
    "\n",
    "* We can use first differences for macro feature selection. This should work. We can use random forests as a feature selection mechanism.\n",
    "\n",
    "* An extra macro variable characterizing market conditions is the number of apartments per time unit (assuming their apartment database is representative of the market). This is basic economics.\n",
    "\n",
    "* Train a classifier that can detect oddly priced apartments (1 mio or 2 mio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Preprocessing Apartment Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes raw sberbank datasets and produces clean training set and test set. This notebook covers the following aspects:\n",
    "* Data type conversion\n",
    "* Feature cleaning\n",
    "* Outlier detection\n",
    "* Removal of obsolete features\n",
    "* Merging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from datetime import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('~/Desktop/sberbank/train.csv')\n",
    "df_test = pd.read_csv('~/Desktop/sberbank/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Check if columns match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_columns(A, B):\n",
    "    return dict(left_only = set(A.columns) - set(B.columns), right_only = set(B.columns)-set(A.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_summary_df(df):\n",
    "    \n",
    "    \"\"\"This function takes a pandas dataframe as an input and outputs a summary data frame. This dataframe can\n",
    "    then be used to fill appropriate data types. \"\"\"\n",
    "    \n",
    "    summary_dict = dict(var_name=[], n_unique=[], sample_val=[], data_type=[])\n",
    "\n",
    "    for i, col in enumerate(df.columns):\n",
    "\n",
    "        summary_dict['var_name'].append(col)\n",
    "        summary_dict['n_unique'].append(len(np.unique(df[col].dropna() )) )\n",
    "        summary_dict['sample_val'].append( reduce(lambda x,y: x+y, [np.random.choice(df[col], size=10)]) )\n",
    "        summary_dict['data_type'].append( str(df.dtypes[i].name) )\n",
    "        \n",
    "    df_out = pd.DataFrame(summary_dict)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change data types, drop ID variables, assign Xy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign X,y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'left_only': set(), 'right_only': set()}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_train.drop(['id', 'price_doc'], axis=1).copy()\n",
    "y_train = df_train.price_doc.copy()\n",
    "X_test  = df_test.drop('id', axis=1).copy()\n",
    "\n",
    "check_columns(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#summary_X_train = make_summary_df(X_train)\n",
    "#summary_X_train.to_csv('summary_X_train.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign column types (target assignment edited in the csv file):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_X_train = pd.read_csv('summary_X_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, var in enumerate(summary_X_train.var_name.values):\n",
    "    X_train[var] = X_train[var].astype(summary_X_train.data_type.values[i])\n",
    "    X_test[var]  = X_test[var].astype(summary_X_train.data_type.values[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exclude variables marked for exclusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sub_area', 'ID_metro', 'ID_railroad_station_walk',\n",
       "       'ID_railroad_station_avto', 'ID_big_road1', 'ID_big_road2'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_X_train.var_name[summary_X_train.exclude==1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop(summary_X_train.var_name[summary_X_train.exclude==1].values, axis=1)\n",
    "X_test = X_test.drop(summary_X_train.var_name[summary_X_train.exclude==1].values, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.timestamp = pd.to_datetime(X_train.timestamp)\n",
    "X_test.timestamp  = pd.to_datetime(X_test.timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function cleans and replaces a few features in the data, as well as inputes NAs for values that are not logical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_date_variables(input_data, date_in_index=False):\n",
    "\n",
    "    if date_in_index:\n",
    "        \n",
    "        #input_data['weeknr'] = map(lambda x: str(x), input_data.index.week)\n",
    "        input_data['year'] = map(lambda x: str(x), input_data.index.year)\n",
    "        input_data['month'] = map(lambda x: str(x), input_data.index.month)\n",
    "\n",
    "        #input_data['week_year'] = input_data['weeknr'] + '_' + input_data['year']\n",
    "        input_data['month_year'] = input_data['month'] + '_' + input_data['year']\n",
    "\n",
    "        return input_data\n",
    "    \n",
    "    else:\n",
    "        output_data = input_data.to_frame(name='timestamp')\n",
    "        \n",
    "        #output_data['weeknr'] = map(lambda x: str(x.week), output_data['timestamp'])\n",
    "        output_data['year'] = map(lambda x: str(x.year), output_data['timestamp'])\n",
    "        output_data['month'] = map(lambda x: str(x.month), output_data['timestamp'])\n",
    "\n",
    "        #output_data['week_year'] = output_data['weeknr'] + '_' + output_data['year']\n",
    "        output_data['month_year'] = output_data['month'] + '_' + output_data['year']\n",
    "\n",
    "        return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_bank(raw_data):\n",
    "    \n",
    "    raw_data_features = raw_data.copy()\n",
    "    \n",
    "    fsq = raw_data_features['full_sq'].copy()\n",
    "    fsq[fsq <8] = np.nan\n",
    "    fsq[fsq >400] = np.nan\n",
    "    raw_data_features['full_sq'] = fsq\n",
    "\n",
    "    lsq = raw_data_features['life_sq'].copy()\n",
    "    lsq[lsq <8] = np.nan\n",
    "    lsq[lsq >400] = np.nan\n",
    "    raw_data_features['life_sq'] = lsq\n",
    "\n",
    "\n",
    "    flr = raw_data_features['floor']\n",
    "    mflr = raw_data_features['max_floor']\n",
    "\n",
    "    flr[flr==0] = np.nan\n",
    "    mflr[mflr==0] = np.nan\n",
    "\n",
    "    raw_data_features['floor']=flr\n",
    "    raw_data_features['max_floor']=mflr\n",
    "\n",
    "    building_type = pd.cut(mflr, np.append(np.arange(0,30), 200), labels=False).astype('object')\n",
    "    raw_data_features['build_type_maxfloor'] = building_type\n",
    "\n",
    "    # make first floor and last floor as separate var\n",
    "    raw_data_features['first_floor'] = flr==1\n",
    "    raw_data_features['last_floor'] = (flr==mflr)\n",
    "\n",
    "    raw_data.loc[raw_data['material']==3, 'material'] = np.nan\n",
    "    raw_data_features['material'] = raw_data['material']\n",
    "\n",
    "    byr = raw_data['build_year'].copy()\n",
    "    byr[(byr<1000) | (byr>2020)]=np.nan \n",
    "    raw_data_features['build_year'] = byr\n",
    "\n",
    "    room_cat = pd.cut(raw_data['num_room'], np.append(np.arange(0,7), 20), labels=False).astype('object')\n",
    "    raw_data_features['num_room']=room_cat\n",
    "\n",
    "    ksq = raw_data['kitch_sq'].copy()\n",
    "    ksq[(ksq>250) | (ksq<2)] = np.nan\n",
    "    raw_data_features['kitch_sq'] = ksq\n",
    "\n",
    "    stat = raw_data['state'].copy()\n",
    "    stat[stat==33] = 3\n",
    "    raw_data_features['state'] = stat\n",
    "    \n",
    "    date_var = extract_date_variables(raw_data_features.timestamp)\n",
    "    raw_data_features = pd.concat([raw_data_features, date_var.iloc[:,1:]], axis=1)\n",
    "    \n",
    "    raw_data_features = raw_data_features.drop('year', axis=1)\n",
    "    \n",
    "    m_counts = raw_data_features.groupby(by='month_year').apply(len).to_frame(name='apt_count')\n",
    "    raw_data_features = raw_data_features.merge(m_counts, left_on='month_year', right_index=True)\n",
    "    \n",
    "    return raw_data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roman/anaconda2/envs/python_cursus/lib/python2.7/site-packages/ipykernel/__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/roman/anaconda2/envs/python_cursus/lib/python2.7/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "X_train_clean = clean_bank(X_train)\n",
    "X_test_clean = clean_bank(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'left_only': set(), 'right_only': set()}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_columns(X_train_clean, X_test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for new factor levels for objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_columns_by_dtype(data, d_type):\n",
    "    \"\"\"This function returns an array of column names of data of the corresponding dtype. \"\"\"\n",
    "    \n",
    "    dtype_series = pd.Series(map(lambda x: x.name, data.dtypes.values) )    \n",
    "    return pd.Series(data.columns).iloc[dtype_series[dtype_series==d_type].index].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_new_factor_levels(train, test):\n",
    "    \"\"\"This function takes training set dataframe and testset dataframe and compares the levels of categorical\n",
    "    variables. If there are unseen factor levels, column name and new level(s) in the testset is returned.\"\"\"\n",
    "    train_fac = train[get_columns_by_dtype(train, 'object') ]\n",
    "    test_fac  = test[get_columns_by_dtype(test, 'object') ]\n",
    "    \n",
    "    test_minus_train = []\n",
    "    for col in train_fac.columns:\n",
    "        test_minus_train.append( set(test_fac[col].dropna().values) - set(train_fac[col].dropna().values) )\n",
    "        \n",
    "    return test_minus_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = check_new_factor_levels(X_train_clean, X_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {'2016'},\n",
       " set(),\n",
       " {'10_2015',\n",
       "  '11_2015',\n",
       "  '12_2015',\n",
       "  '1_2016',\n",
       "  '2_2016',\n",
       "  '3_2016',\n",
       "  '4_2016',\n",
       "  '5_2016',\n",
       "  '7_2015',\n",
       "  '8_2015',\n",
       "  '9_2015'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_clean.to_csv('AptFeatures_train.csv')\n",
    "X_test_clean.to_csv('AptFeatures_test.csv')\n",
    "y_train.to_csv('target_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually corrected the monthly quantity in the trainset to na in first two months !!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python_cursus]",
   "language": "python",
   "name": "conda-env-python_cursus-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
